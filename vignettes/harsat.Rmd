---
title: "Getting started"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Getting started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---



## Getting started

For now, we will assume that you are familiar with running basic R scripts
and so on. We will focus on what the structure of a typical what the code 
looks like in a typical analysis.

## Installing `harsat` from GitHub

To install the latest development version, use the `remotes` package:

```
library(remotes)
remotes::install_github("osparcomm/harsat", auth_token = 'XXXX') 
```

> Note: during development the repository is marked as private on GitHub, so you
> will need a Personal Access Token (or PAT) to access it. Follow
> [these instructions to create a Personal Access Token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens#creating-a-fine-grained-personal-access-token).
> It'll be a short string, probably beginning with `ghp_`. Put the whole
> string into the `auth_token` parameter, and that should install the 
> `harsat` package directly.

> Note: many of the functions currently have a `cstm` prefix. When the
> code was originally developed, we thought of it as "contaminant time series modelling", 
> which is why you get all these `cstm` prefixes. These will be removed in the 
> near future.

## Loading the code

Now, within R, you can load the library in the usual way


```r
library(harsat)
```

## Accessing files

How you organize your files is up to you. We will start from the current working directory.
We'll detect that using R's `here` package, and write it into a variable `working.directory`. 


```r
library(here)
working.directory <- here()
```


## Reading in the data

The first step is to read in the data that we've got.
We will go through some of these arguments.


```r
biota_data <- read_data(
  compartment = "biota", 
  purpose = "OSPAR",                               
  contaminants = "test_data.csv", 
  stations = "station_dictionary.csv", 
  QA = "quality_assurance.csv",
  data_dir = file.path(working.directory, "data", "example_simple_OSPAR"),
  data_format = "ICES_old",
  info_files = list(
    determinand = "determinand_simple_OSPAR.csv", 
    thresholds = "thresholds_biota_simple_OSPAR.csv"
  ),
  info_dir = file.path(working.directory, "information"), 
  extraction = "2022/01/11",
  max_year = 2020L
)
#> Reading station dictionary from:
#>  '/Users/stuart/git/HARSAT/data/example_simple_OSPAR/station_dictionary.csv'
#> 
#> Reading contaminant and biological effects data from:
#>  '/Users/stuart/git/HARSAT/data/example_simple_OSPAR/test_data.csv'
#> 
#> Reading QA data from '/Users/stuart/git/HARSAT/data/example_simple_OSPAR/quality_assurance.csv'
```

The main arguments here are as follows:

* `compartment` is an argument which specifies whether we're dealing with a 
  biota assessment, a sediment assessment, or a water assessment.
* `purpose` means we can mirror an `OSPAR` style assessment, a `HELCOM` style assessment, 
  an `AMAP`-style assessment, or `other` which means you can basically tailor it yourself 
  and the idea is that the code will be sufficiently flexible that you can do a lot of 
  tailoring to suit your own needs.
* `contaminants` is a data file which has all the chemical measurements in it.
* `stations` is the station file which is directly related to the station dictionary 
  that we get out at from ICES.
* `QA` is a quality assurance file -- this is *deprecated* and will disappear.
* `info_files` are reference tables -- we come back to that.

This reads in the three data sets, but does no more than that at this stage.

Once you get to this point, you can look at the data if you want to, or 
do anything else that you need with the data before proceeding. 
Essentially the files that come in at this point are unchanged from the files that we are reading them in from.
This is basically just reading in the data and setting things up.

At this point we might want to do a whole lot of *ad hoc* corrections to these data,
as is done with the OSPAR estimates. 

## Tidying the data

The next step is to clean the data to prepare for analysis. This step tidies up the 
data structures that we've got there. It does filtering so that we get data in the
 form that we want for say, an OSPAR assessment or a HELCOM assessment.
It also streamlines some of the data files.

This may generate warnings. For example, when we're cleaning the station dictionary, 
we've may find some issues with duplicate stations. Similarly, when it comes to cleaning the contaminant and biological effects data, 
we've may find some data from stations which are unrecognized by the station dictionary. Sometimes that's fine and sometimes that's not.
Warnings are supported by output files which allow you to come in and have a look and 
see which values are affected, so you can go and check them out in more detail.


```r
biota_data <- ctsm_tidy_data(biota_data)
#> 
#> Oddities will be written to 'oddities/biota' with previous oddities backed up to
#>  'oddities/biota_backup'
#> 
#> Cleaning station dictionary
#>    Duplicate stations - first one selected: see duplicate_stations.csv
#> 
#> Cleaning contaminant and biological effects data
#>    Submitted.station unrecognised by dictionary: see stations_unrecognised.csv
#>    Dropping data with no stations
```

To this point, we've still not done anything with the datasets.

## Create time series

Now we can group the data into time series. This means identifying which data points 
belong to the same time series, and then set it up as a structure which then allows us 
to do the assessments.

There are various different ways in which we can specify which determinants we actually 
want to assess. In this case, the `determinands` parameter specifies cadmium, CP153, CB153, HBCD, HBCDA,
HBCDG, and some biological metabolites. There are various other arguments which allow you to control 
just how the data are manipulated.


```r
biota_timeSeries <- ctsm_create_timeSeries(
  biota_data,
  determinands = c("CD", "CB153", "HBCD","HBCDA", "HBCDG", "PYR1OH"),
  determinands.control = list(
    HBCD = list(det = c("HBCDA", "HBCDB", "HBCDG"), action = "sum"),
    "LIPIDWT%" = list(det = c("EXLIP%", "FATWT%"), action = "bespoke")
  ),
  get_basis = get_basis_biota_OSPAR
)
#> 
#> Oddities will be written to 'oddities/biota' with previous oddities backed up to
#>  'oddities/biota_backup'
#> 
#> Cleaning data
#>    Dropping stations with no data between 2015 and 2020 
#>    Dropping samples with only auxiliary variables
#>    Unexpected or missing values for 'matrix': see matrix_queries.csv
#>    Unexpected or missing values for 'basis': see basis_queries.csv
#>    Bile metabolite units changed from 'ng/g' to 'ng/ml' and from 'ug/kg' to 'ug/l'
#>    Replicate measurements, only first retained: see replicate_measurements.csv
#>    Limit of quantification less than limit of detection: see limits_inconsistent.csv
#>    Detection limit higher than data: see detection_limit_high.csv
#>    Data submitted as HBCDA, HBCDB, HBCDG summed to give HBCD
#>    Data submitted as EXLIP% or FATWT% relabelled as LIPIDWT% 
#> 
#> Creating time series data
#>    Converting data to appropriate basis for statistical analysis
#>    Losing 32 out of 392 records in basis conversion due to missing, censored
#>    or zero drywt or lipidwt values.
#>    Dropping bivalve and gastropod contaminant data collected during the
#>     spawning season, which is taken to be the following months:
#>     April, May, June, July 
#>    Dropping groups of compounds / stations with no data between 2015 and 2020
```

## Assessment

The next the next stage is to do the assessment.

We've created a time series object, and pass that into this call.
We have to say which thresholds we're going to use when we do the assessment and there are other options which we can put in here.
But this will just run.
You can see that it tells you which time series we're actually assessing as it progresses.
This gives you an idea of how how many cups of tea you can drink before it's all finished.


```r
biota_assessment <- run_assessment(
  biota_timeSeries,
  AC = c("BAC", "EAC", "EQS", "HQS")
)
#> 
#> assessing series:  station_code 11461; determinand CB153; species Mytilus edulis; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 11461; determinand CD; species Mytilus edulis; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 12156; determinand CD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 12164; determinand CB153; species Crassostrea gigas; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 12164; determinand CD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 1235; determinand CB153; species Crassostrea gigas; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 1235; determinand CD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg
#> boundary (singular) fit: see help('isSingular')
#> boundary (singular) fit: see help('isSingular')
#> boundary (singular) fit: see help('isSingular')
#> boundary (singular) fit: see help('isSingular')
#> 
#> assessing series:  station_code 1235; determinand HBCD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 1235; determinand HBCDA; species Crassostrea gigas; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 1235; determinand HBCDG; species Crassostrea gigas; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 13059; determinand CB153; species Spisula solida; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 13059; determinand CD; species Spisula solida; matrix SB; basis D; unit ug/kg
#> boundary (singular) fit: see help('isSingular')
#> boundary (singular) fit: see help('isSingular')
#> 
#> assessing series:  station_code 1345; determinand CB153; species Crassostrea gigas; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 1345; determinand CD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg
#> boundary (singular) fit: see help('isSingular')
#> boundary (singular) fit: see help('isSingular')
#> boundary (singular) fit: see help('isSingular')
#> boundary (singular) fit: see help('isSingular')
#> 
#> assessing series:  station_code 1345; determinand HBCD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 1345; determinand HBCDA; species Crassostrea gigas; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 1345; determinand HBCDG; species Crassostrea gigas; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 1381; determinand CB153; species Mytilus edulis; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 1381; determinand CD; species Mytilus edulis; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 1381; determinand HBCD; species Mytilus edulis; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 1381; determinand HBCDA; species Mytilus edulis; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 1381; determinand HBCDG; species Mytilus edulis; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 1388; determinand CB153; species Crassostrea gigas; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 1388; determinand CD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg
#> boundary (singular) fit: see help('isSingular')
#> boundary (singular) fit: see help('isSingular')
#> boundary (singular) fit: see help('isSingular')
#> 
#> assessing series:  station_code 2717; determinand PYR1OH; species Limanda limanda; matrix BI; method_analysis HPLC-FD; unit ng/ml 
#> 
#> assessing series:  station_code 3282; determinand CB153; species Crassostrea gigas; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 3282; determinand CD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 3433; determinand CB153; species Mytilus edulis; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 3433; determinand CD; species Mytilus edulis; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 3441; determinand CB153; species Mytilus edulis; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 3441; determinand CD; species Mytilus edulis; matrix SB; basis D; unit ug/kg
#> boundary (singular) fit: see help('isSingular')
#> boundary (singular) fit: see help('isSingular')
#> 
#> assessing series:  station_code 7132; determinand CB153; species Mytilus edulis; matrix SB; basis D; unit ug/kg 
#> 
#> assessing series:  station_code 7132; determinand CD; species Mytilus edulis; matrix SB; basis D; unit ug/kg
```

There are various little warnings: these ones are nothing to worry about.

We can then check that everything is converged.


```r
check_convergence_lmm(biota_assessment$assessment)
#> [1] 0
```

## Reporting

We can then get a summary table of our results. We want a direcrory where
we can put it. And `harsat` won't create a directory if there's nothing
there, so let's make a new directory, `./output/tutorial`, and put the full
path into `summary.dir`, so we can tell `harsat` where to write to.


```r
summary.dir <- file.path(working.directory, "output", "tutorial")

if (!dir.exists(summary.dir)) {
  dir.create(summary.dir, recursive = TRUE)
}
```

Next, we set up a few variables to manage the display.


```r
webGroups <- list(
  levels = c("Metals", "Metabolites", "Organobromines", "Chlorobiphenyls"),  
  labels = c(
    "Metals", "PAH metabolites", "Organobromines",  "Polychlorinated biphenyls"
  )
)

classColour <- list(
  below = c(
    "BAC" = "blue", 
    "EAC" = "green", 
    "EQS" = "green",
    "HQS" = "green"
  ),
  above = c(
    "BAC" = "orange", 
    "EAC" = "red", 
    "EQS" = "red",
    "HQS" = "red"
  ), 
  none = "black"
)
```

And then we can generate the summary proper.
The summary file which will be very familiar to those who have been involved in the OSPAR and the HELCOM
assessments. The summary files have information about each time series, 
what the time series represents (which is the first set of columns), followed
by statistical results, such as p values, and summary values such as the number of years in the data set,
when it starts and finishes. And towards the end, we've got comparisons against various different threshold values.


```r
write_summary_table(
  biota_assessment, 
  determinandGroups = webGroups,
  classColour = classColour,
  collapse_AC = list(EAC = c("EAC", "EQS")),
  output_dir = summary.dir 
)
```

